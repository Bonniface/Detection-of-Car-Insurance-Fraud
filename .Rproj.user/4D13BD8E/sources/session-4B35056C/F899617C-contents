---
title: "Cliam Fraud"
author: "BonnyFace Kalong"
date: "`r Sys.Date()`"
output: pData_document
---

```{r}
Data<-read.csv("./DataSet/fraud_oracle.csv")
head(Data)
```

```{r}
skimr::skim(Data)
```
```{r}

```

```{r,warning=FALSE}
library(ggplot2)
library(gridExtra)

# Create a list of countplots
plots <- list(
  ggplot(Data, aes(x=Month, fill=FraudFound_P)) + 
    geom_bar(position="dodge") + 
    scale_x_discrete(limits=c('Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec')) + 
    labs(title="Month"),
  
  ggplot(Data, aes(x=DayOfWeek, fill=FraudFound_P)) + 
    geom_bar(position="dodge") + 
    scale_x_discrete(limits=c('Sunday','Monday','Tuesday','Wednesday','Thursday','Friday','Saturday')) + 
    labs(title="Day"),
  
  ggplot(Data, aes(x=Sex, fill=FraudFound_P)) + 
    geom_bar(position="dodge") + 
    labs(title="Sex"),
  
  ggplot(Data, aes(x=MaritalStatus, fill=FraudFound_P)) + 
    geom_bar(position="dodge") + 
    labs(title="Marital Status"),
  
  ggplot(Data, aes(x=NumberOfCars, fill=FraudFound_P)) + 
    geom_bar(position="dodge") + 
    labs(title="Number Of Cars"),
  
  ggplot(Data, aes(x=AccidentArea, fill=FraudFound_P)) + 
    geom_bar(position="dodge") + 
    labs(title="Accident Area"),
  
  ggplot(Data, aes(x=DriverRating, fill=FraudFound_P)) + 
    geom_bar(position="dodge") + 
    labs(title="Driver Rating"),
  
  ggplot(Data, aes(x=AgentType, fill=FraudFound_P)) + 
    geom_bar(position="dodge") + 
    labs(title="Agent Type"),
  
  ggplot(Data, aes(x=BasePolicy, fill=FraudFound_P)) + 
    geom_bar(position="dodge") + 
    labs(title="Base Policy")
)

# Arrange the plots in a grid
grid.arrange(
  grobs = plots,
  ncol = 3,
  nrow = 3,
  top = "Countplots of Categorical Variables by Fraud Found",
  widths = c(10, 10, 10),
  heights = c(5, 5, 5)
)

```
```{r}
# library(ggplot2)
# library(gridExtra)
# df <- Data
# pdf("countplots.pdf", width = 15, height = 10)
# 
# p1 <- ggplot(df, aes(x=Month, fill=FraudFound_P)) + 
#   geom_bar(position="dodge") + 
#   scale_x_discrete(limits=c('Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec')) + 
#   labs(title="Month")
# 
# p2 <- ggplot(df, aes(x=DayOfWeek, fill=FraudFound_P)) + 
#   geom_bar(position="dodge") + 
#   scale_x_discrete(limits=c('Sunday','Monday','Tuesday','Wednesday','Thursday','Friday','Saturday')) + 
#   labs(title="Day")
# 
# p3 <- ggplot(df, aes(x=Sex, fill=FraudFound_P)) + 
#   geom_bar(position="dodge") + 
#   labs(title="Sex")
# 
# p4 <- ggplot(df, aes(x=MaritalStatus, fill=FraudFound_P)) + 
#   geom_bar(position="dodge") + 
#   labs(title="Marital Status")
# 
# p5 <- ggplot(df, aes(x=NumberOfCars, fill=FraudFound_P)) + 
#   geom_bar(position="dodge") + 
#   labs(title="Number Of Cars")
# 
# p6 <- ggplot(df, aes(x=AccidentArea, fill=FraudFound_P)) + 
#   geom_bar(position="dodge") + 
#   labs(title="Accident Area")
# 
# p7 <- ggplot(df, aes(x=DriverRating, fill=FraudFound_P)) + 
#   geom_bar(position="dodge") + 
#   labs(title="Driver Rating")
# 
# p8 <- ggplot(df, aes(x=AgentType, fill=FraudFound_P)) + 
#   geom_bar(position="dodge") + 
#   labs(title="Agent Type")
# 
# p9 <- ggplot(df, aes(x=BasePolicy, fill=FraudFound_P)) + 
#   geom_bar(position="dodge") + 
#   labs(title="Base Policy")
# 
# grid.arrange(p1, p2, p3, p4, p5, p6, p7, p8, p9, ncol=3, nrow=3, top="Countplots of Categorical Variables by Fraud Found")
# 
# dev.off()

```

```{r,warning=FALSE,message=FALSE message=FALSE, r,warning=FALSE}
library(tidyverse)
# find categorical variables
cat_vars <- sapply(Data, class) %>% 
  .[. != "numeric" & . != "integer" & . != "double"] %>% 
  names()

# count unique values in each categorical variable
cat_counts <- lapply(Data[, cat_vars], function(x) length(unique(x)))

# combine variable names and counts into a data frame
cat_summary <- data.frame(
  Variable = names(cat_counts),
  Unique_Count = unlist(cat_counts)
)

# print results
cat_summary
```
```{r}
library(metan)
plot(corr_coef(Data))
```

```{r}
non_collinear_vars(Data,max_vif = 5,Age,Year,PolicyNumber,WeekOfMonthClaimed,WeekOfMonth,DriverRating,RepNumber,FraudFound_P)
```
```{r}
library(dplyr)
library(caret)
# Encode categorical variables using dummyVars function
formula <- as.formula("FraudFound_P ~ .")
encoded_data <- predict(dummyVars(formula, data = Data), newdata = Data)
```

```{r}
# Normalize numerical variables
num_cols <- sapply(Data, is.numeric)
num_data <- Data[, num_cols]
# Normalize numerical variables (excluding target variable)
preprocessParams <- preProcess(num_data %>% select(-FraudFound_P), method = c("center", "scale"))
norm_num_data <- predict(preprocessParams, num_data)

# Combine encoded and normalized data frames
processed_data <- cbind(norm_num_data, encoded_data)
processed_data$FraudFound_P <- factor(processed_data$FraudFound_P , levels = c(0, 1))

```
```{r}
# Convert level names to valid R variable names
levels(processed_data$FraudFound_P) <- make.names(levels(processed_data$FraudFound_P))

# Check the level names
levels(processed_data$FraudFound_P)
```


```{r}
# Split data into training, validation, and testing sets
set.seed(123)  # for reproducibility
inTrain <- createDataPartition(processed_data$FraudFound_P, p = 0.7, list = FALSE)
training <- processed_data[inTrain, ]
remaining <- processed_data[-inTrain, ]
inTest <- createDataPartition(remaining$FraudFound_P, p = 0.5, list = FALSE)
validation <- remaining[inTest, ]
testing <- remaining[-inTest, ]
```

```{r}
library(nnet)

# Rename duplicated columns in the training, validation, and testing data frames
names(training) <- make.names(names(training), unique=TRUE)
names(validation) <- make.names(names(validation), unique=TRUE)
names(testing) <- make.names(names(testing), unique=TRUE)

# Create formula for modeling
formula <- as.formula("FraudFound_P ~ .")
```
```{r}
library(xgboost)

# Define the grid of hyperparameters to search
hyperparams <- expand.grid(
  max_depth = c(1, 2, 3, 4),
  eta = c(0.1, 0.3, 0.5),
  gamma = c(0, 0.2, 0.5),
  colsample_bytree = c(0.5, 0.8),
  min_child_weight = c(1, 3),
  subsample = c(0.5, 0.8),
  nrounds = c(50, 100, 200, 300)
)
```

```{r,warning=FALSE}
# Train and tune the XGBoost model using cross-validation
set.seed(123)
ctrl <- trainControl(method = "cv", number = 2, verboseIter = TRUE, allowParallel = TRUE, classProbs = TRUE)
model1 <- train(
  FraudFound_P ~ .,
  data = training,
  trControl = ctrl,
  # tuneGrid = hyperparams,
  method = "xgbTree",
  metric = "AUC",
  tuneLength = 2, # number of combinations to try in hyperparameter tuning
  verbose = TRUE,
  objective = "binary:logistic", # specify objective for binary classification
  eval_metric = "auc" # specify evaluation metric for binary classification
)
```
```{r}

# Print the best hyperparameters and model performance
print(model1$bestTune)
print(model1$results)
print(model1$finalModel)

```
```{r}
validation$FraudFound_P <- as.numeric(as.character(validation$FraudFound_P))
validation$FraudFound_P <- factor(validation$FraudFound_P , levels = c(0, 1))
# Convert level names to valid R variable names
levels(validation$FraudFound_P) <- make.names(levels(validation$FraudFound_P))

# Check the level names
levels(validation$FraudFound_P)
```

```{r}
# Evaluate the model performance on the testing set
library(pROC)

# Make predictions on the testing set
pred <- predict(model1, validation)

# Convert predicted values to a factor with the same levels as actual values
pred <- factor(ifelse(pred >= 0.5, "1", "0"), levels = levels(validation$FraudFound_P))

# Convert actual values to a factor with the same levels as predicted values
actual <- factor(validation$FraudFound_P, levels = levels(pred))


# Compute and print the confusion matrix
confusionMatrix(actual, pred)
```
```{r}
# Compute and print the AUC
auc <- roc(validation$FraudFound, pred)$auc
cat("AUC:", auc, "\n")

# Plot the ROC curve
plot(roc(validation$FraudFound, pred), main = "ROC Curve", print.thres = c(0.1, 0.25, 0.5, 0.75, 0.9))


```
```{r}
# Plot the ROC curve
plot(auc, print.thres = "best", main = "ROC Curve")
```
```{r}
# Compute the confusion matrix and print it
confusionMatrix(pred, validation$FraudFound_P)
```
```{r}
# Plot the feature importance
xgb.importance(model1 = model1$finalModel) 

```

```{r}
# Train and tune the XGBoost model using cross-validation
set.seed(123)
ctrl <- trainControl(method = "cv", number = 2, verboseIter = TRUE, allowParallel = TRUE, classProbs = TRUE)
model2 <- train(
  FraudFound_P ~ .,
  data = training,
  trControl = ctrl,
  tuneGrid = hyperparams,
  method = "xgbTree",
  metric = "AUC",
  tuneLength = 2, # number of combinations to try in hyperparameter tuning
  verbose = TRUE,
  objective = "binary:logistic", # specify objective for binary classification
  eval_metric = "auc" # specify evaluation metric for binary classification
)


# Print the best hyperparameters and model performance
print(model2$bestTune)
print(model2$results)
print(model2$finalModel)
```







































